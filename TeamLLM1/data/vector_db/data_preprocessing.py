import pandas as pd
import faiss
from sentence_transformers import SentenceTransformer
import torch
import os
from dotenv import load_dotenv

def build_faiss_index(input_path: str, output_path: str, model_name: str):
    """
    CSV íŒŒì¼ë¡œë¶€í„° í…ìŠ¤íŠ¸ë¥¼ ì½ì–´ë“¤ì—¬ FAISS ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        input_path (str): ì…ë ¥ CSV íŒŒì¼ ê²½ë¡œ.
        output_path (str): ìƒì„±ëœ FAISS ì¸ë±ìŠ¤ë¥¼ ì €ì¥í•  íŒŒì¼ ê²½ë¡œ.
        model_name (str): ì‚¬ìš©í•  Sentence Transformer ëª¨ë¸ ì´ë¦„.
    """
    # --- 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ---
    print(f"ğŸ”„ [1/5] '{input_path}' íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤...")
    try:
        df = pd.read_csv(input_path)
    except FileNotFoundError:
        print(f"ì—ëŸ¬: ì…ë ¥ íŒŒì¼ '{input_path}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print("[2/5] ì„ë² ë”©í•  í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤...")
    df['text_for_embedding'] = df['ë²•ë ¹ëª…'].astype(str) + " " + \
                               df['ì¡°ë¬¸ ë²ˆí˜¸'].astype(str) + " " + \
                               df['ì¡°ë¬¸ ë‚´ìš©'].astype(str)
    texts = df['text_for_embedding'].tolist()
    print("ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ.")
    print("-" * 50)

    # --- 2. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ---
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"[3/5] ì„ë² ë”© ëª¨ë¸ '{model_name}'ì„(ë¥¼) ë¡œë“œí•©ë‹ˆë‹¤... ({device} ì‚¬ìš©)")
    model = SentenceTransformer(model_name, device=device)
    print("ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")
    print("-" * 50)

    # --- 3. í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± ---
    print(f"[4/5] ì´ {len(texts)}ê°œì˜ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤...")
    embeddings = model.encode(texts, convert_to_tensor=True, show_progress_bar=True)
    embeddings_np = embeddings.cpu().numpy()
    print(f"í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± ì™„ë£Œ. ë²¡í„° ì°¨ì›: {embeddings_np.shape}")
    print("-" * 50)

    # --- 4. FAISS ì¸ë±ìŠ¤ êµ¬ì¶• ë° ì €ì¥ ---
    print("[5/5] FAISS ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤...")
    embedding_dim = embeddings_np.shape[1]
    index = faiss.IndexFlatL2(embedding_dim)
    index.add(embeddings_np)
    
    output_dir = os.path.dirname(output_path)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir)
        
    faiss.write_index(index, output_path)
    print(f"FAISS ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ.")
    print(f"   - ì´ {index.ntotal}ê°œì˜ ë²¡í„°ê°€ ì¸ë±ìŠ¤ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"   - '{output_path}' íŒŒì¼ë¡œ ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ.")


if __name__ == '__main__':
    # .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
    load_dotenv()

    # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì •ê°’ ê°€ì ¸ì˜¤ê¸°
    input_csv_path = os.getenv("FAISS_INPUT_DATA")
    faiss_index_path = os.getenv("FAISS_OUTPUT_DATA")
    output_path = os.path.join(faiss_index_path , "db.index")
    embedding_model = os.getenv("EMBEDDING_MODEL")

    print(output_path)
    # í™˜ê²½ë³€ìˆ˜ê°€ ì œëŒ€ë¡œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸
    if not all([input_csv_path, output_path, embedding_model]):
        raise ValueError("í™˜ê²½ë³€ìˆ˜(INPUT_CSV_PATH, FAISS_INDEX_PATH, EMBEDDING_MODEL)ë¥¼ .env íŒŒì¼ì— ì„¤ì •í•´ì£¼ì„¸ìš”.")
    
    # ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰
    build_faiss_index(
        input_path=input_csv_path,
        output_path=output_path,
        model_name=embedding_model
    )